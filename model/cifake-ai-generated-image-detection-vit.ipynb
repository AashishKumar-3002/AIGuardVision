{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":5256696,"sourceType":"datasetVersion","datasetId":3041726}],"dockerImageVersionId":30559,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import libraries, load and transform data","metadata":{}},{"cell_type":"code","source":"!pip list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Install necessary Python packages using pip\n\n# Use the 'pip' command to install packages\n# The '-q' flag stands for 'quiet,' which means it will suppress most output, making the installation process less verbose\n# We're installing the following packages:\n# - 'evaluate': This package is likely used for evaluation purposes, but the specific functionality is not clear from this line alone\n# - 'transformers': This package is commonly used for natural language processing tasks, such as working with pre-trained language models like BERT or GPT\n# - 'datasets': This package provides easy access to various datasets commonly used in machine learning and natural language processing tasks\n# - 'mlflow': MLflow is an open-source platform for managing the end-to-end machine learning lifecycle, including tracking experiments, packaging code into reproducible runs, and sharing and deploying models\n\n# Note: Before running this code, make sure you have Python and pip installed on your system.\n# Also, ensure you have an internet connection since pip will download and install these packages from PyPI (Python Package Index).\n!pip install -U imblearn pandas==2.2.1 pillow==10.2.0 pyarrow==15.0.2 pyarrow-hotfix==0.6 scikit-learn==1.4.1.post1 evaluate==0.4.1 transformers==4.39.3 datasets==2.18.0 accelerate==0.28.0 mlflow 2>/dev/null","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install torch --upgrade torchaudio torchmetrics torchvision tqdm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras-cv==0.8.2 keras-nlp==0.8.2 numpy==1.26.4 shapely>=2.0.1 tokenizers==0.15.2 jupyterlab==3.6.0 huggingface-hub==0.22.2 imbalanced-learn==0.12.2 jupyter-lsp>=2.0.0 jupyterlab>=4.1.0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pip uninstall datasets -y","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall evaluate -y","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:33:21.780144Z","iopub.execute_input":"2024-04-02T16:33:21.780748Z","iopub.status.idle":"2024-04-02T16:33:23.578671Z","shell.execute_reply.started":"2024-04-02T16:33:21.780717Z","shell.execute_reply":"2024-04-02T16:33:23.577464Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Found existing installation: evaluate 0.4.1\nUninstalling evaluate-0.4.1:\n  Successfully uninstalled evaluate-0.4.1\n","output_type":"stream"}]},{"cell_type":"code","source":"!conda install evaluate -y","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:33:35.710396Z","iopub.execute_input":"2024-04-02T16:33:35.711495Z","iopub.status.idle":"2024-04-02T16:36:27.435676Z","shell.execute_reply.started":"2024-04-02T16:33:35.711457Z","shell.execute_reply":"2024-04-02T16:36:27.434691Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Retrieving notices: ...working... done\nCollecting package metadata (current_repodata.json): | WARNING conda.models.version:get_matcher(556): Using .* with relational operator is superfluous and deprecated and will be removed in a future version of conda. Your spec was 1.7.1.*, but conda is ignoring the .* and treating it as 1.7.1\ndone\nSolving environment: done\n\n\n==> WARNING: A newer version of conda exists. <==\n  current version: 23.7.4\n  latest version: 24.3.0\n\nPlease update conda by running\n\n    $ conda update -n base -c conda-forge conda\n\nOr to minimize the number of packages updated during conda update use\n\n     conda install conda=24.3.0\n\n\n\n## Package Plan ##\n\n  environment location: /opt/conda\n\n  added / updated specs:\n    - evaluate\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    binaryornot-0.4.4          |             py_1         370 KB  conda-forge\n    chardet-5.2.0              |  py310hff52083_1         241 KB  conda-forge\n    cookiecutter-2.6.0         |     pyhca7485f_0          98 KB  conda-forge\n    datasets-2.12.0            |  py310h06a4308_0         643 KB\n    dill-0.3.5.1               |     pyhd8ed1ab_0          71 KB  conda-forge\n    evaluate-0.4.1             |     pyhd8ed1ab_0          61 KB  conda-forge\n    filelock-3.13.3            |     pyhd8ed1ab_0          15 KB  conda-forge\n    huggingface_hub-0.22.2     |     pyhd8ed1ab_0         237 KB  conda-forge\n    multiprocess-0.70.14       |  py310h5764c6d_2         221 KB  conda-forge\n    openssl-3.2.1              |       hd590300_1         2.7 MB  conda-forge\n    python-slugify-8.0.4       |     pyhd8ed1ab_0          15 KB  conda-forge\n    python-xxhash-3.4.1        |  py310h2372a71_0          23 KB  conda-forge\n    responses-0.18.0           |     pyhd8ed1ab_0          35 KB  conda-forge\n    text-unidecode-1.3         |     pyhd8ed1ab_1          64 KB  conda-forge\n    xxhash-0.8.2               |       hd590300_0          95 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:         4.9 MB\n\nThe following NEW packages will be INSTALLED:\n\n  binaryornot        conda-forge/noarch::binaryornot-0.4.4-py_1 \n  chardet            conda-forge/linux-64::chardet-5.2.0-py310hff52083_1 \n  cookiecutter       conda-forge/noarch::cookiecutter-2.6.0-pyhca7485f_0 \n  datasets           pkgs/main/linux-64::datasets-2.12.0-py310h06a4308_0 \n  dill               conda-forge/noarch::dill-0.3.5.1-pyhd8ed1ab_0 \n  evaluate           conda-forge/noarch::evaluate-0.4.1-pyhd8ed1ab_0 \n  filelock           conda-forge/noarch::filelock-3.13.3-pyhd8ed1ab_0 \n  huggingface_hub    conda-forge/noarch::huggingface_hub-0.22.2-pyhd8ed1ab_0 \n  multiprocess       conda-forge/linux-64::multiprocess-0.70.14-py310h5764c6d_2 \n  python-slugify     conda-forge/noarch::python-slugify-8.0.4-pyhd8ed1ab_0 \n  python-xxhash      conda-forge/linux-64::python-xxhash-3.4.1-py310h2372a71_0 \n  responses          conda-forge/noarch::responses-0.18.0-pyhd8ed1ab_0 \n  text-unidecode     conda-forge/noarch::text-unidecode-1.3-pyhd8ed1ab_1 \n  xxhash             conda-forge/linux-64::xxhash-0.8.2-hd590300_0 \n\nThe following packages will be UPDATED:\n\n  openssl                                  3.2.1-hd590300_0 --> 3.2.1-hd590300_1 \n\n\n\nDownloading and Extracting Packages\nopenssl-3.2.1        | 2.7 MB    |                                       |   0% \nfilelock-3.13.3      | 15 KB     |                                       |   0% \u001b[A\n\npython-xxhash-3.4.1  | 23 KB     |                                       |   0% \u001b[A\u001b[A\n\n\ncookiecutter-2.6.0   | 98 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\n\n\n\ntext-unidecode-1.3   | 64 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nevaluate-0.4.1       | 61 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nresponses-0.18.0     | 35 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nxxhash-0.8.2         | 95 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nbinaryornot-0.4.4    | 370 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nchardet-5.2.0        | 241 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ndill-0.3.5.1         | 71 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\ndatasets-2.12.0      | 643 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nmultiprocess-0.70.14 | 221 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npython-slugify-8.0.4 | 15 KB     |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nhuggingface_hub-0.22 | 237 KB    |                                       |   0% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\npython-xxhash-3.4.1  | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\n\npython-xxhash-3.4.1  | 23 KB     | ##################################### | 100% \u001b[A\u001b[A\n\n\nopenssl-3.2.1        | 2.7 MB    | 2                                     |   1% \u001b[A\u001b[A\u001b[A\nfilelock-3.13.3      | 15 KB     | ##################################### | 100% \u001b[A\n\n\n\ntext-unidecode-1.3   | 64 KB     | #########3                            |  25% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nevaluate-0.4.1       | 61 KB     | #########6                            |  26% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nresponses-0.18.0     | 35 KB     | ################8                     |  45% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nxxhash-0.8.2         | 95 KB     | ######2                               |  17% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nbinaryornot-0.4.4    | 370 KB    | #6                                    |   4% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nopenssl-3.2.1        | 2.7 MB    | ###################2                  |  52% \u001b[A\n\n\n\n\n\n\n\n\nchardet-5.2.0        | 241 KB    | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ntext-unidecode-1.3   | 64 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\ntext-unidecode-1.3   | 64 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ndill-0.3.5.1         | 71 KB     | ########3                             |  22% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\ndatasets-2.12.0      | 643 KB    | 9                                     |   2% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npython-slugify-8.0.4 | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nmultiprocess-0.70.14 | 221 KB    | ##6                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nhuggingface_hub-0.22 | 237 KB    | ##4                                   |   7% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nresponses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\nresponses-0.18.0     | 35 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nevaluate-0.4.1       | 61 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\nevaluate-0.4.1       | 61 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nxxhash-0.8.2         | 95 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\nxxhash-0.8.2         | 95 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nchardet-5.2.0        | 241 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\nchardet-5.2.0        | 241 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\ncookiecutter-2.6.0   | 98 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\ncookiecutter-2.6.0   | 98 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nbinaryornot-0.4.4    | 370 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\nbinaryornot-0.4.4    | 370 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\npython-slugify-8.0.4 | 15 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ndill-0.3.5.1         | 71 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\ndill-0.3.5.1         | 71 KB     | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nmultiprocess-0.70.14 | 221 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\nopenssl-3.2.1        | 2.7 MB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nhuggingface_hub-0.22 | 237 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\nhuggingface_hub-0.22 | 237 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\ndatasets-2.12.0      | 643 KB    | ##################################### | 100% \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n                                                                                \u001b[A\n\n                                                                                \u001b[A\u001b[A\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n\n\n\n\n\n\n\n\n\n\n\n\n\n                                                                                \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n","output_type":"stream"}]},{"cell_type":"code","source":"# Importing necessary libraries and modules\nimport warnings  # Import the 'warnings' module for handling warnings\nwarnings.filterwarnings(\"ignore\")  # Ignore warnings during execution\n\nimport gc  # Import the 'gc' module for garbage collection\nimport numpy as np  # Import NumPy for numerical operations\nimport pandas as pd  # Import Pandas for data manipulation\nimport itertools  # Import 'itertools' for iterators and looping\nfrom collections import Counter  # Import 'Counter' for counting elements\nimport matplotlib.pyplot as plt  # Import Matplotlib for data visualization\nfrom sklearn.metrics import (  # Import various metrics from scikit-learn\n    accuracy_score,  # For calculating accuracy\n    roc_auc_score,  # For ROC AUC score\n    confusion_matrix,  # For confusion matrix\n    classification_report,  # For classification report\n    f1_score  # For F1 score\n)\n\n# Import custom modules and classes\nfrom imblearn.over_sampling import RandomOverSampler # import RandomOverSampler\nimport accelerate # Import the 'accelerate' module\nimport evaluate  # Import the 'evaluate' module\nfrom datasets import Dataset, Image, ClassLabel  # Import custom 'Dataset', 'ClassLabel', and 'Image' classes\nfrom transformers import (  # Import various modules from the Transformers library\n    TrainingArguments,  # For training arguments\n    Trainer,  # For model training\n    ViTImageProcessor,  # For processing image data with ViT models\n    ViTForImageClassification,  # ViT model for image classification\n    DefaultDataCollator  # For collating data in the default way\n)\nimport torch  # Import PyTorch for deep learning\nfrom torch.utils.data import DataLoader  # For creating data loaders\nfrom torchvision.transforms import (  # Import image transformation functions\n    CenterCrop,  # Center crop an image\n    Compose,  # Compose multiple image transformations\n    Normalize,  # Normalize image pixel values\n    RandomRotation,  # Apply random rotation to images\n    RandomResizedCrop,  # Crop and resize images randomly\n    RandomHorizontalFlip,  # Apply random horizontal flip\n    RandomAdjustSharpness,  # Adjust sharpness randomly\n    Resize,  # Resize images\n    ToTensor  # Convert images to PyTorch tensors\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:38:21.693294Z","iopub.execute_input":"2024-04-02T16:38:21.693748Z","iopub.status.idle":"2024-04-02T16:38:32.559428Z","shell.execute_reply.started":"2024-04-02T16:38:21.693711Z","shell.execute_reply":"2024-04-02T16:38:32.558560Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stderr","text":"2024-04-02 16:38:23.774166: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-02 16:38:23.774276: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-02 16:38:23.910120: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import the necessary module from the Python Imaging Library (PIL).\nfrom PIL import ImageFile\n\n# Enable the option to load truncated images.\n# This setting allows the PIL library to attempt loading images even if they are corrupted or incomplete.\nImageFile.LOAD_TRUNCATED_IMAGES = True","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:19.009801Z","iopub.execute_input":"2024-04-02T16:39:19.011101Z","iopub.status.idle":"2024-04-02T16:39:19.015576Z","shell.execute_reply.started":"2024-04-02T16:39:19.011065Z","shell.execute_reply":"2024-04-02T16:39:19.014575Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# use https://huggingface.co/docs/datasets/image_load for reference\n\n# Import necessary libraries\nimage_dict = {}\n\n# Define the list of file names\nfrom pathlib import Path\nfrom tqdm import tqdm\nimport os\n# Initialize empty lists to store file names and labels\nfile_names = []\nlabels = []\n\n# Iterate through all image files in the specified directory\nfor file in sorted((Path('/kaggle/input/cifake-real-and-ai-generated-synthetic-images/').glob('*/*/*.*'))):\n    label = str(file).split('/')[-2]  # Extract the label from the file path\n    labels.append(label)  # Add the label to the list\n    file_names.append(str(file))  # Add the file path to the list\n\n# Print the total number of file names and labels\nprint(len(file_names), len(labels))\n\n# Create a pandas dataframe from the collected file names and labels\ndf = pd.DataFrame.from_dict({\"image\": file_names, \"label\": labels})\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:22.416715Z","iopub.execute_input":"2024-04-02T16:39:22.417093Z","iopub.status.idle":"2024-04-02T16:39:31.027736Z","shell.execute_reply.started":"2024-04-02T16:39:22.417065Z","shell.execute_reply":"2024-04-02T16:39:31.026712Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"120000 120000\n(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:34.489896Z","iopub.execute_input":"2024-04-02T16:39:34.490624Z","iopub.status.idle":"2024-04-02T16:39:34.504387Z","shell.execute_reply.started":"2024-04-02T16:39:34.490590Z","shell.execute_reply":"2024-04-02T16:39:34.503353Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"                                               image label\n0  /kaggle/input/cifake-real-and-ai-generated-syn...  FAKE\n1  /kaggle/input/cifake-real-and-ai-generated-syn...  FAKE\n2  /kaggle/input/cifake-real-and-ai-generated-syn...  FAKE\n3  /kaggle/input/cifake-real-and-ai-generated-syn...  FAKE\n4  /kaggle/input/cifake-real-and-ai-generated-syn...  FAKE","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/cifake-real-and-ai-generated-syn...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/cifake-real-and-ai-generated-syn...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/cifake-real-and-ai-generated-syn...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/cifake-real-and-ai-generated-syn...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/cifake-real-and-ai-generated-syn...</td>\n      <td>FAKE</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df['label'].unique()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:37.854883Z","iopub.execute_input":"2024-04-02T16:39:37.855676Z","iopub.status.idle":"2024-04-02T16:39:37.871380Z","shell.execute_reply.started":"2024-04-02T16:39:37.855645Z","shell.execute_reply":"2024-04-02T16:39:37.870411Z"},"trusted":true},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"array(['FAKE', 'REAL'], dtype=object)"},"metadata":{}}]},{"cell_type":"code","source":"# random oversampling of minority class\n# 'y' contains the target variable (label) we want to predict\ny = df[['label']]\n\n# Drop the 'label' column from the DataFrame 'df' to separate features from the target variable\ndf = df.drop(['label'], axis=1)\n\n# Create a RandomOverSampler object with a specified random seed (random_state=83)\nros = RandomOverSampler(random_state=83)\n\n# Use the RandomOverSampler to resample the dataset by oversampling the minority class\n# 'df' contains the feature data, and 'y_resampled' will contain the resampled target variable\ndf, y_resampled = ros.fit_resample(df, y)\n\n# Delete the original 'y' variable to save memory as it's no longer needed\ndel y\n\n# Add the resampled target variable 'y_resampled' as a new 'label' column in the DataFrame 'df'\ndf['label'] = y_resampled\n\n# Delete the 'y_resampled' variable to save memory as it's no longer needed\ndel y_resampled\n\n# Perform garbage collection to free up memory used by discarded variables\ngc.collect()\n\nprint(df.shape)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:40.264850Z","iopub.execute_input":"2024-04-02T16:39:40.265978Z","iopub.status.idle":"2024-04-02T16:39:41.403455Z","shell.execute_reply.started":"2024-04-02T16:39:40.265924Z","shell.execute_reply":"2024-04-02T16:39:41.402414Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"(120000, 2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a dataset from a Pandas DataFrame.\ndataset = Dataset.from_pandas(df).cast_column(\"image\", Image())","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:46.490032Z","iopub.execute_input":"2024-04-02T16:39:46.490688Z","iopub.status.idle":"2024-04-02T16:39:46.554630Z","shell.execute_reply.started":"2024-04-02T16:39:46.490657Z","shell.execute_reply":"2024-04-02T16:39:46.553560Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"# Display the first image in the dataset\ndataset[0][\"image\"]","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:47.390046Z","iopub.execute_input":"2024-04-02T16:39:47.390694Z","iopub.status.idle":"2024-04-02T16:39:47.415349Z","shell.execute_reply.started":"2024-04-02T16:39:47.390663Z","shell.execute_reply":"2024-04-02T16:39:47.414438Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDkdN8PmXHFdLD4Xjit2nuHWOFBlnc4AFXtPvNJtlBluoiR/DGd5P5Vh+IdbnvvHOjaeC8GmxXEEhhJwWO7O5v8O1bR5mcrcFpcvf2PpU0W+Kd3Ujhlt5Cp/Hbis+48NRyxebbuskeSNy+orqPEnjDwnBZWGn6vFfTCLdta0ABU45B3Ed/5VQ0zxb4d1aNNJ0o6iroryD7WFIVR2BB+pqufTQagjyOyiv7rMSLM3r1AHvWxZWs1prkErlnS2miaZ+pBJ46eprZ07xKWjCSSEjGOtJdRQ3crzR3UiO+M8gjjpwRg/lXJCnKM+a+g/Zo9Dt7eG/1IB54dPMVp/qp7MMsrdNx3L/CSM4/vVga145tNG8RXFlH4O0tJopzbl42KsQe/A71zKT6jFepcG/tZiilQJYzGcE+qGnajqV5dXAuHjsvMGD8l5PtYgAZKnjtz61stCz//2Q=="},"metadata":{}}]},{"cell_type":"code","source":"# Extracting a subset of elements from the 'labels' list using slicing.\n# The slicing syntax [:5] selects elements from the beginning up to (but not including) the 5th element.\n# This will give us the first 5 elements of the 'labels' list.\n# The result will be a new list containing these elements.\nlabels_subset = labels[:5]\n\n# Printing the subset of labels to inspect the content.\nprint(labels_subset)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:48.384594Z","iopub.execute_input":"2024-04-02T16:39:48.385326Z","iopub.status.idle":"2024-04-02T16:39:48.390296Z","shell.execute_reply.started":"2024-04-02T16:39:48.385296Z","shell.execute_reply":"2024-04-02T16:39:48.389354Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"['FAKE', 'FAKE', 'FAKE', 'FAKE', 'FAKE']\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a list of unique labels by converting 'labels' to a set and then back to a list\nlabels_list = ['REAL', 'FAKE'] #list(set(labels))\n\n# Initialize empty dictionaries to map labels to IDs and vice versa\nlabel2id, id2label = dict(), dict()\n\n# Iterate over the unique labels and assign each label an ID, and vice versa\nfor i, label in enumerate(labels_list):\n    label2id[label] = i  # Map the label to its corresponding ID\n    id2label[i] = label  # Map the ID to its corresponding label\n\n# Print the resulting dictionaries for reference\nprint(\"Mapping of IDs to Labels:\", id2label, '\\n')\nprint(\"Mapping of Labels to IDs:\", label2id)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:50.424358Z","iopub.execute_input":"2024-04-02T16:39:50.425305Z","iopub.status.idle":"2024-04-02T16:39:50.431699Z","shell.execute_reply.started":"2024-04-02T16:39:50.425267Z","shell.execute_reply":"2024-04-02T16:39:50.430733Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Mapping of IDs to Labels: {0: 'REAL', 1: 'FAKE'} \n\nMapping of Labels to IDs: {'REAL': 0, 'FAKE': 1}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Creating classlabels to match labels to IDs\nClassLabels = ClassLabel(num_classes=len(labels_list), names=labels_list)\n\n# Mapping labels to IDs\ndef map_label2id(example):\n    example['label'] = ClassLabels.str2int(example['label'])\n    return example\n\ndataset = dataset.map(map_label2id, batched=True)\n\n# Casting label column to ClassLabel Object\ndataset = dataset.cast_column('label', ClassLabels)\n\n# Splitting the dataset into training and testing sets using an 90-10 split ratio.\ndataset = dataset.train_test_split(test_size=0.1, shuffle=True, stratify_by_column=\"label\")\n\n# Extracting the training data from the split dataset.\ntrain_data = dataset['train']\n\n# Extracting the testing data from the split dataset.\ntest_data = dataset['test']","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:51.999923Z","iopub.execute_input":"2024-04-02T16:39:52.000689Z","iopub.status.idle":"2024-04-02T16:39:52.569468Z","shell.execute_reply.started":"2024-04-02T16:39:52.000658Z","shell.execute_reply":"2024-04-02T16:39:52.568696Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Casting the dataset:   0%|          | 0/120000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"# Define the pre-trained ViT model string\nmodel_str = \"dima806/ai_vs_real_image_detection\" #'google/vit-base-patch16-224-in21k'\n\n# Create a processor for ViT model input from the pre-trained model\nprocessor = ViTImageProcessor.from_pretrained(model_str)\n\n# Retrieve the image mean and standard deviation used for normalization\nimage_mean, image_std = processor.image_mean, processor.image_std\n\n# Get the size (height) of the ViT model's input images\nsize = processor.size[\"height\"]\nprint(\"Size: \", size)\n\n# Define a normalization transformation for the input images\nnormalize = Normalize(mean=image_mean, std=image_std)\n\n# Define a set of transformations for training data\n_train_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        RandomRotation(90),               # Apply random rotation\n        RandomAdjustSharpness(2),         # Adjust sharpness randomly\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a set of transformations for validation data\n_val_transforms = Compose(\n    [\n        Resize((size, size)),             # Resize images to the ViT model's input size\n        ToTensor(),                       # Convert images to tensors\n        normalize                         # Normalize images using mean and std\n    ]\n)\n\n# Define a function to apply training transformations to a batch of examples\ndef train_transforms(examples):\n    examples['pixel_values'] = [_train_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples\n\n# Define a function to apply validation transformations to a batch of examples\ndef val_transforms(examples):\n    examples['pixel_values'] = [_val_transforms(image.convert(\"RGB\")) for image in examples['image']]\n    return examples","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:53.309693Z","iopub.execute_input":"2024-04-02T16:39:53.310463Z","iopub.status.idle":"2024-04-02T16:39:53.597324Z","shell.execute_reply.started":"2024-04-02T16:39:53.310431Z","shell.execute_reply":"2024-04-02T16:39:53.596408Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/325 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"202af1d772a646c8a5e2b39d46d125b8"}},"metadata":{}},{"name":"stdout","text":"Size:  224\n","output_type":"stream"}]},{"cell_type":"code","source":"# Set the transforms for the training data\ntrain_data.set_transform(train_transforms)\n\n# Set the transforms for the test/validation data\ntest_data.set_transform(val_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:56.189250Z","iopub.execute_input":"2024-04-02T16:39:56.189752Z","iopub.status.idle":"2024-04-02T16:39:56.196718Z","shell.execute_reply.started":"2024-04-02T16:39:56.189720Z","shell.execute_reply":"2024-04-02T16:39:56.195395Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Define a collate function that prepares batched data for model training.\ndef collate_fn(examples):\n    # Stack the pixel values from individual examples into a single tensor.\n    pixel_values = torch.stack([example[\"pixel_values\"] for example in examples])\n    \n    # Convert the label strings in examples to corresponding numeric IDs using label2id dictionary.\n    labels = torch.tensor([example['label'] for example in examples])\n    \n    # Return a dictionary containing the batched pixel values and labels.\n    return {\"pixel_values\": pixel_values, \"labels\": labels}","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:39:57.774841Z","iopub.execute_input":"2024-04-02T16:39:57.775628Z","iopub.status.idle":"2024-04-02T16:39:57.781119Z","shell.execute_reply.started":"2024-04-02T16:39:57.775594Z","shell.execute_reply":"2024-04-02T16:39:57.780094Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"markdown","source":"# Load, train, and evaluate model","metadata":{}},{"cell_type":"code","source":"# Create a ViTForImageClassification model from a pretrained checkpoint with a specified number of output labels.\nmodel = ViTForImageClassification.from_pretrained(model_str, num_labels=len(labels_list))\n\n# Configure the mapping of class labels to their corresponding indices for later reference.\nmodel.config.id2label = id2label\nmodel.config.label2id = label2id\n\n# Calculate and print the number of trainable parameters in millions for the model.\nprint(model.num_parameters(only_trainable=True) / 1e6)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:40:00.249103Z","iopub.execute_input":"2024-04-02T16:40:00.249864Z","iopub.status.idle":"2024-04-02T16:40:02.655174Z","shell.execute_reply.started":"2024-04-02T16:40:00.249828Z","shell.execute_reply":"2024-04-02T16:40:02.654194Z"},"trusted":true},"execution_count":18,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/720 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1f69a0ed76024ac98f5bf6d978fca9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"843e37d5ee5d423ea2a788436250a886"}},"metadata":{}},{"name":"stdout","text":"85.800194\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the accuracy metric from a module named 'evaluate'\naccuracy = evaluate.load(\"accuracy\")\n\n# Define a function 'compute_metrics' to calculate evaluation metrics\ndef compute_metrics(eval_pred):\n    # Extract model predictions from the evaluation prediction object\n    predictions = eval_pred.predictions\n    \n    # Extract true labels from the evaluation prediction object\n    label_ids = eval_pred.label_ids\n    \n    # Calculate accuracy using the loaded accuracy metric\n    # Convert model predictions to class labels by selecting the class with the highest probability (argmax)\n    predicted_labels = predictions.argmax(axis=1)\n    \n    # Calculate accuracy score by comparing predicted labels to true labels\n    acc_score = accuracy.compute(predictions=predicted_labels, references=label_ids)['accuracy']\n    \n    # Return the computed accuracy as a dictionary with the key \"accuracy\"\n    return {\n        \"accuracy\": acc_score\n    }","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:40:06.875140Z","iopub.execute_input":"2024-04-02T16:40:06.875541Z","iopub.status.idle":"2024-04-02T16:40:07.691555Z","shell.execute_reply.started":"2024-04-02T16:40:06.875490Z","shell.execute_reply":"2024-04-02T16:40:07.690735Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"90692c01d5834ea5bd411b1c90bb3c2c"}},"metadata":{}}]},{"cell_type":"code","source":"# Define the name of the evaluation metric to be used during training and evaluation.\nmetric_name = \"accuracy\"\n\n# Define the name of the model, which will be used to create a directory for saving model checkpoints and outputs.\nmodel_name = \"AIvisionGuard\"\n\n# Define the number of training epochs for the model.\nnum_train_epochs = 1\n\n# Create an instance of TrainingArguments to configure training settings.\nargs = TrainingArguments(\n    # Specify the directory where model checkpoints and outputs will be saved.\n    output_dir=model_name,\n    \n    # Specify the directory where training logs will be stored.\n    logging_dir='./logs',\n    \n    # Define the evaluation strategy, which is performed at the end of each epoch.\n    evaluation_strategy=\"epoch\",\n    \n    # Set the learning rate for the optimizer.\n    learning_rate=3e-6,\n    \n    # Define the batch size for training on each device.\n    per_device_train_batch_size=64,\n    \n    # Define the batch size for evaluation on each device.\n    per_device_eval_batch_size=32,\n    \n    # Specify the total number of training epochs.\n    num_train_epochs=num_train_epochs,\n    \n    # Apply weight decay to prevent overfitting.\n    weight_decay=0.02,\n    \n    # Set the number of warm-up steps for the learning rate scheduler.\n    warmup_steps=50,\n    \n    # Disable the removal of unused columns from the dataset.\n    remove_unused_columns=False,\n    \n    # Define the strategy for saving model checkpoints (per epoch in this case).\n    save_strategy='epoch',\n    \n    # Load the best model at the end of training.\n    load_best_model_at_end=True,\n    \n    # Limit the total number of saved checkpoints to save space.\n    save_total_limit=1,\n    \n    # Specify that training progress should not be reported .\n    report_to=\"none\"  # log to none\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:43:07.769939Z","iopub.execute_input":"2024-04-02T16:43:07.770759Z","iopub.status.idle":"2024-04-02T16:43:07.827122Z","shell.execute_reply.started":"2024-04-02T16:43:07.770722Z","shell.execute_reply":"2024-04-02T16:43:07.826128Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Create a Trainer instance for fine-tuning a language model.\n\n# - `model`: The pre-trained language model to be fine-tuned.\n# - `args`: Configuration settings and hyperparameters for training.\n# - `train_dataset`: The dataset used for training the model.\n# - `eval_dataset`: The dataset used for evaluating the model during training.\n# - `data_collator`: A function that defines how data batches are collated and processed.\n# - `compute_metrics`: A function for computing custom evaluation metrics.\n# - `tokenizer`: The tokenizer used for processing text data.\n\ntrainer = Trainer(\n    model,\n    args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    data_collator=collate_fn,\n    compute_metrics=compute_metrics,\n    tokenizer=processor,\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:43:12.855863Z","iopub.execute_input":"2024-04-02T16:43:12.856497Z","iopub.status.idle":"2024-04-02T16:43:13.092333Z","shell.execute_reply.started":"2024-04-02T16:43:12.856466Z","shell.execute_reply":"2024-04-02T16:43:13.091550Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Evaluate the pre-training model's performance on a test dataset.\n# This function calculates various metrics such as accuracy, loss, etc.,\n# to assess how well the model is performing on unseen data.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:43:13.969272Z","iopub.execute_input":"2024-04-02T16:43:13.970018Z","iopub.status.idle":"2024-04-02T16:46:39.632021Z","shell.execute_reply.started":"2024-04-02T16:43:13.969981Z","shell.execute_reply":"2024-04-02T16:46:39.631038Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='750' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [375/375 58:50]\n    </div>\n    "},"metadata":{}},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.04799602925777435,\n 'eval_accuracy': 0.9825833333333334,\n 'eval_runtime': 205.656,\n 'eval_samples_per_second': 58.35,\n 'eval_steps_per_second': 1.823}"},"metadata":{}}]},{"cell_type":"code","source":"# Start training the model using the trainer object.\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T16:46:39.634023Z","iopub.execute_input":"2024-04-02T16:46:39.634467Z","iopub.status.idle":"2024-04-02T17:42:07.375901Z","shell.execute_reply.started":"2024-04-02T16:46:39.634433Z","shell.execute_reply":"2024-04-02T17:42:07.374900Z"},"trusted":true},"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1688' max='1688' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1688/1688 55:24, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Accuracy</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.038300</td>\n      <td>0.048101</td>\n      <td>0.982083</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1688, training_loss=0.039481821218373084, metrics={'train_runtime': 3327.3373, 'train_samples_per_second': 32.458, 'train_steps_per_second': 0.507, 'total_flos': 8.369134878375936e+18, 'train_loss': 0.039481821218373084, 'epoch': 1.0})"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the post-training model's performance on the validation or test dataset.\n# This function computes various evaluation metrics like accuracy, loss, etc.\n# and provides insights into how well the model is performing.\n\ntrainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:42:07.377135Z","iopub.execute_input":"2024-04-02T17:42:07.377401Z","iopub.status.idle":"2024-04-02T17:44:02.374330Z","shell.execute_reply.started":"2024-04-02T17:42:07.377377Z","shell.execute_reply":"2024-04-02T17:44:02.373473Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.04810093343257904,\n 'eval_accuracy': 0.9820833333333333,\n 'eval_runtime': 114.9911,\n 'eval_samples_per_second': 104.356,\n 'eval_steps_per_second': 3.261,\n 'epoch': 1.0}"},"metadata":{}}]},{"cell_type":"code","source":"# Use the trained 'trainer' to make predictions on the 'test_data'.\noutputs = trainer.predict(test_data)\n\n# Print the metrics obtained from the prediction outputs.\nprint(outputs.metrics)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:44:09.861459Z","iopub.execute_input":"2024-04-02T17:44:09.862338Z","iopub.status.idle":"2024-04-02T17:45:53.802557Z","shell.execute_reply.started":"2024-04-02T17:44:09.862304Z","shell.execute_reply":"2024-04-02T17:45:53.801626Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"{'test_loss': 0.04810093343257904, 'test_accuracy': 0.9820833333333333, 'test_runtime': 103.9336, 'test_samples_per_second': 115.458, 'test_steps_per_second': 3.608}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Extract the true labels from the model outputs\ny_true = outputs.label_ids\n\n# Predict the labels by selecting the class with the highest probability\ny_pred = outputs.predictions.argmax(1)\n\n# Define a function to plot a confusion matrix\ndef plot_confusion_matrix(cm, classes, title='Confusion Matrix', cmap=plt.cm.Blues, figsize=(10, 8)):\n    \"\"\"\n    This function plots a confusion matrix.\n\n    Parameters:\n        cm (array-like): Confusion matrix as returned by sklearn.metrics.confusion_matrix.\n        classes (list): List of class names, e.g., ['Class 0', 'Class 1'].\n        title (str): Title for the plot.\n        cmap (matplotlib colormap): Colormap for the plot.\n    \"\"\"\n    # Create a figure with a specified size\n    plt.figure(figsize=figsize)\n    \n    # Display the confusion matrix as an image with a colormap\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    # Define tick marks and labels for the classes on the axes\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.0f'\n    # Add text annotations to the plot indicating the values in the cells\n    thresh = cm.max() / 2.0\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt), horizontalalignment=\"center\", color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    # Label the axes\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\n    # Ensure the plot layout is tight\n    plt.tight_layout()\n    # Display the plot\n    plt.show()\n\n# Calculate accuracy and F1 score\naccuracy = accuracy_score(y_true, y_pred)\nf1 = f1_score(y_true, y_pred, average='macro')\n\n# Display accuracy and F1 score\nprint(f\"Accuracy: {accuracy:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\n\n# Get the confusion matrix if there are a small number of labels\nif len(labels_list) <= 150:\n    # Compute the confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Plot the confusion matrix using the defined function\n    plot_confusion_matrix(cm, labels_list, figsize=(8, 6))\n    \n# Finally, display classification report\nprint()\nprint(\"Classification report:\")\nprint()\nprint(classification_report(y_true, y_pred, target_names=labels_list, digits=4))","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:46:09.504106Z","iopub.execute_input":"2024-04-02T17:46:09.504549Z","iopub.status.idle":"2024-04-02T17:46:09.863554Z","shell.execute_reply.started":"2024-04-02T17:46:09.504487Z","shell.execute_reply":"2024-04-02T17:46:09.862584Z"},"trusted":true},"execution_count":26,"outputs":[{"name":"stdout","text":"Accuracy: 0.9821\nF1 Score: 0.9821\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 2 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"\nClassification report:\n\n              precision    recall  f1-score   support\n\n        REAL     0.9806    0.9837    0.9821      6000\n        FAKE     0.9836    0.9805    0.9821      6000\n\n    accuracy                         0.9821     12000\n   macro avg     0.9821    0.9821    0.9821     12000\nweighted avg     0.9821    0.9821    0.9821     12000\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Save the trained model: This line of code is responsible for saving the model\n# that has been trained using the trainer object. It will serialize the model\n# and its associated weights, making it possible to reload and use the model\n# in the future without the need to retrain it.\ntrainer.save_model()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:46:17.215465Z","iopub.execute_input":"2024-04-02T17:46:17.216300Z","iopub.status.idle":"2024-04-02T17:46:17.764145Z","shell.execute_reply.started":"2024-04-02T17:46:17.216269Z","shell.execute_reply":"2024-04-02T17:46:17.763107Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"# Import the 'pipeline' function from the 'transformers' library.\nfrom transformers import pipeline\n\n# Create a pipeline for image classification tasks. \n# You need to specify the 'model_name' and the 'device' to use for inference.\n# - 'model_name': The name of the pre-trained model to be used for image classification.\n# - 'device': Specifies the device to use for running the model (0 for GPU, -1 for CPU).\npipe = pipeline('image-classification', model=model_name, device=0)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:47:11.656861Z","iopub.execute_input":"2024-04-02T17:47:11.657606Z","iopub.status.idle":"2024-04-02T17:47:12.465575Z","shell.execute_reply.started":"2024-04-02T17:47:11.657573Z","shell.execute_reply":"2024-04-02T17:47:12.464749Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Accessing an image from the 'test_data' dataset using index 1.\nimage = test_data[1][\"image\"]\n\n# Displaying the 'image' variable.\nimage","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:47:15.460962Z","iopub.execute_input":"2024-04-02T17:47:15.461343Z","iopub.status.idle":"2024-04-02T17:47:15.473348Z","shell.execute_reply.started":"2024-04-02T17:47:15.461313Z","shell.execute_reply":"2024-04-02T17:47:15.472476Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=32x32>","image/png":"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","image/jpeg":"/9j/4AAQSkZJRgABAQAAAQABAAD/2wBDAAgGBgcGBQgHBwcJCQgKDBQNDAsLDBkSEw8UHRofHh0aHBwgJC4nICIsIxwcKDcpLDAxNDQ0Hyc5PTgyPC4zNDL/2wBDAQkJCQwLDBgNDRgyIRwhMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjIyMjL/wAARCAAgACADASIAAhEBAxEB/8QAHwAAAQUBAQEBAQEAAAAAAAAAAAECAwQFBgcICQoL/8QAtRAAAgEDAwIEAwUFBAQAAAF9AQIDAAQRBRIhMUEGE1FhByJxFDKBkaEII0KxwRVS0fAkM2JyggkKFhcYGRolJicoKSo0NTY3ODk6Q0RFRkdISUpTVFVWV1hZWmNkZWZnaGlqc3R1dnd4eXqDhIWGh4iJipKTlJWWl5iZmqKjpKWmp6ipqrKztLW2t7i5usLDxMXGx8jJytLT1NXW19jZ2uHi4+Tl5ufo6erx8vP09fb3+Pn6/8QAHwEAAwEBAQEBAQEBAQAAAAAAAAECAwQFBgcICQoL/8QAtREAAgECBAQDBAcFBAQAAQJ3AAECAxEEBSExBhJBUQdhcRMiMoEIFEKRobHBCSMzUvAVYnLRChYkNOEl8RcYGRomJygpKjU2Nzg5OkNERUZHSElKU1RVVldYWVpjZGVmZ2hpanN0dXZ3eHl6goOEhYaHiImKkpOUlZaXmJmaoqOkpaanqKmqsrO0tba3uLm6wsPExcbHyMnK0tPU1dbX2Nna4uPk5ebn6Onq8vP09fb3+Pn6/9oADAMBAAIRAxEAPwDze08EX9yARNFtP8Qyf54rTX4aXjDP26Mf9sj/AI13mmBSo6VT8W6rqGkQRzWDRf6tw6uwGCejc+m1q5VKTOtwijkD8Mr0DP2+P/v0f8aqzfD68hBP2yM/9sz/AI16/G6zW8cqkFXQMCO4IzWbf4CnpQ5yQKESjpUo2jmqXizRbnxBcWMCYjt1+R5kODgnLbh3AwMfWqVlqCqgw1aTXqzRqDIwKnIKnHOMf1qCzV0gmy0qKwlBD2qiMEnIZR9059xVbUbhdp5rk9Vi1RZ2urHU5Q3H7kuSrfmayZ/EerbCLnTm46lDj9Oarlb6k81nsf/Z"},"metadata":{}}]},{"cell_type":"code","source":"# Apply the 'pipe' function to process the 'image' variable.\npipe(image)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:47:20.806117Z","iopub.execute_input":"2024-04-02T17:47:20.806741Z","iopub.status.idle":"2024-04-02T17:47:20.832480Z","shell.execute_reply.started":"2024-04-02T17:47:20.806707Z","shell.execute_reply":"2024-04-02T17:47:20.831581Z"},"trusted":true},"execution_count":30,"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"[{'label': 'FAKE', 'score': 0.9985300302505493},\n {'label': 'REAL', 'score': 0.001469960669055581}]"},"metadata":{}}]},{"cell_type":"code","source":"# This line of code accesses the \"label\" attribute of a specific element in the test_data list.\n# It's used to retrieve the actual label associated with a test data point.\nid2label[test_data[1][\"label\"]]","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:47:45.201013Z","iopub.execute_input":"2024-04-02T17:47:45.202106Z","iopub.status.idle":"2024-04-02T17:47:45.213294Z","shell.execute_reply.started":"2024-04-02T17:47:45.202061Z","shell.execute_reply":"2024-04-02T17:47:45.212380Z"},"trusted":true},"execution_count":31,"outputs":[{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"'FAKE'"},"metadata":{}}]},{"cell_type":"markdown","source":"# Send model to Huggingface","metadata":{}},{"cell_type":"code","source":"# Import the necessary module to interact with the Hugging Face Hub.\nfrom huggingface_hub import notebook_login\n\n# Perform a login to the Hugging Face Hub.\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:50:43.350813Z","iopub.execute_input":"2024-04-02T17:50:43.351241Z","iopub.status.idle":"2024-04-02T17:50:43.375335Z","shell.execute_reply.started":"2024-04-02T17:50:43.351214Z","shell.execute_reply":"2024-04-02T17:50:43.374448Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f3a746af72c47baa759e02b475d5f35"}},"metadata":{}}]},{"cell_type":"code","source":"# Import the HfApi class from the huggingface_hub library.\nfrom huggingface_hub import HfApi\n\n# Create an instance of the HfApi class.\napi = HfApi()\n\n# Define the repository ID by combining the username \"dima806\" with the model name.\nrepo_id = f\"AashishKumar/{model_name}\"\n\ntry:\n    # Attempt to create a new repository on the Hugging Face Model Hub using the specified repo_id.\n    api.create_repo(repo_id)\n    \n    # If the repository creation is successful, print a message indicating that the repository was created.\n    print(f\"Repo {repo_id} created\")\nexcept:\n    # If an exception is raised, print a message indicating that the repository already exists.\n    print(f\"Repo {repo_id} already exists\")","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:51:21.606226Z","iopub.execute_input":"2024-04-02T17:51:21.606928Z","iopub.status.idle":"2024-04-02T17:51:28.574688Z","shell.execute_reply.started":"2024-04-02T17:51:21.606888Z","shell.execute_reply":"2024-04-02T17:51:28.573708Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Repo AashishKumar/AIvisionGuard created\n","output_type":"stream"}]},{"cell_type":"code","source":"# Uploading a folder to the Hugging Face Model Hub\napi.upload_folder(\n    folder_path=model_name,  # The path to the folder to be uploaded\n    path_in_repo=\".\",  # The path where the folder will be stored in the repository\n    repo_id=repo_id,  # The ID of the repository where the folder will be uploaded\n    repo_type=\"model\",  # The type of the repository (in this case, a model repository)\n    revision=\"main\" # Revision name\n)","metadata":{"execution":{"iopub.status.busy":"2024-04-02T17:51:34.331230Z","iopub.execute_input":"2024-04-02T17:51:34.331624Z","iopub.status.idle":"2024-04-02T17:52:06.973743Z","shell.execute_reply.started":"2024-04-02T17:51:34.331595Z","shell.execute_reply":"2024-04-02T17:52:06.972774Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"optimizer.pt:   0%|          | 0.00/687M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"64eaf3b8a2ae47d8b5999a58c7113f3d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scheduler.pt:   0%|          | 0.00/1.06k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"183c94276f44437a8599709afeb45046"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"51c3ba87f210419c8b948f607d586946"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"rng_state.pth:   0%|          | 0.00/14.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d8dfe4f0c1c4fd0ae77cfd3a69d9704"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 7 LFS files:   0%|          | 0/7 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"518f249e7eef4366bf318733e97c3945"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c331f0c20067446ba9005a3624f831d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/343M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a307452935f49b0803ec7e3890c0398"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7daf634c9df4401e865146a826804380"}},"metadata":{}},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AashishKumar/AIvisionGuard/commit/2ac81de8d1f91e3a9ff7b70856794c51b01b6b8e', commit_message='Upload folder using huggingface_hub', commit_description='', oid='2ac81de8d1f91e3a9ff7b70856794c51b01b6b8e', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}